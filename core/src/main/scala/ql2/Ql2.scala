// Generated by ScalaBuff, the Scala Protocol Buffers compiler. DO NOT EDIT!
// source: ql2.proto

package ql2

final case class VersionDummy (

) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[VersionDummy] {



	def writeTo(output: com.google.protobuf.CodedOutputStream) {
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): VersionDummy = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}

		def __newMerged = VersionDummy(

		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: VersionDummy) = {
		VersionDummy(

		)
	}

	def getDefaultInstanceForType = VersionDummy.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
}

object VersionDummy {
	@reflect.BeanProperty val defaultInstance = new VersionDummy()

	def parseFrom(data: Array[Byte]): VersionDummy = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): VersionDummy = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): VersionDummy = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): VersionDummy = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[VersionDummy] = defaultInstance.mergeDelimitedFromStream(stream)


	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: VersionDummy) = defaultInstance.mergeFrom(prototype)

	object Version extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val V0_1 = new EnumVal { val name = "V0_1"; val id = 1063369270 }
		val V0_2 = new EnumVal { val name = "V0_2"; val id = 1915781601 }

		val V0_1_VALUE = 1063369270
		val V0_2_VALUE = 1915781601

		def valueOf(id: Int) = id match {
			case 1063369270 => V0_1
			case 1915781601 => V0_2
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

}
final case class Query (
	`type`: Option[Query.QueryType.EnumVal] = None,
	`query`: Option[Term] = None,
	`token`: Option[Long] = None,
	`OBSOLETENoreply`: Option[Boolean] = Some(false),
	`globalOptargs`: collection.immutable.Seq[Query.AssocPair] = Vector.empty[Query.AssocPair]
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Query] {

	def setType(_f: Query.QueryType.EnumVal) = copy(`type` = Some(_f))
	def setQuery(_f: Term) = copy(`query` = Some(_f))
	def setToken(_f: Long) = copy(`token` = Some(_f))
	def setOBSOLETENoreply(_f: Boolean) = copy(`OBSOLETENoreply` = Some(_f))
	def setGlobalOptargs(_i: Int, _v: Query.AssocPair) = copy(`globalOptargs` = `globalOptargs`.updated(_i, _v))
	def addGlobalOptargs(_f: Query.AssocPair) = copy(`globalOptargs` = `globalOptargs` :+ _f)
	def addAllGlobalOptargs(_f: Query.AssocPair*) = copy(`globalOptargs` = `globalOptargs` ++ _f)
	def addAllGlobalOptargs(_f: TraversableOnce[Query.AssocPair]) = copy(`globalOptargs` = `globalOptargs` ++ _f)

	def clearType = copy(`type` = None)
	def clearQuery = copy(`query` = None)
	def clearToken = copy(`token` = None)
	def clearOBSOLETENoreply = copy(`OBSOLETENoreply` = None)
	def clearGlobalOptargs = copy(`globalOptargs` = Vector.empty[Query.AssocPair])

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		if (`type`.isDefined) output.writeEnum(1, `type`.get)
		if (`query`.isDefined) output.writeMessage(2, `query`.get)
		if (`token`.isDefined) output.writeInt64(3, `token`.get)
		if (`OBSOLETENoreply`.isDefined) output.writeBool(4, `OBSOLETENoreply`.get)
		for (_v <- `globalOptargs`) output.writeMessage(6, _v)
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0
		if (`type`.isDefined) size += computeEnumSize(1, `type`.get)
		if (`query`.isDefined) size += computeMessageSize(2, `query`.get)
		if (`token`.isDefined) size += computeInt64Size(3, `token`.get)
		if (`OBSOLETENoreply`.isDefined) size += computeBoolSize(4, `OBSOLETENoreply`.get)
		for (_v <- `globalOptargs`) size += computeMessageSize(6, _v)

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Query = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __type: Option[Query.QueryType.EnumVal] = `type`
		var __query: Option[Term] = `query`
		var __token: Option[Long] = `token`
		var __OBSOLETENoreply: Option[Boolean] = `OBSOLETENoreply`
		val __globalOptargs: collection.mutable.Buffer[Query.AssocPair] = `globalOptargs`.toBuffer

		def __newMerged = Query(
			__type,
			__query,
			__token,
			__OBSOLETENoreply,
			Vector(__globalOptargs: _*)
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 8 => __type = Some(Query.QueryType.valueOf(in.readEnum()))
			case 18 => __query = Some(readMessage[Term](in, __query.orElse({
				__query = Term.defaultInstance
				__query
			}).get, _emptyRegistry))
			case 24 => __token = Some(in.readInt64())
			case 32 => __OBSOLETENoreply = Some(in.readBool())
			case 50 => __globalOptargs += readMessage[Query.AssocPair](in, Query.AssocPair.defaultInstance, _emptyRegistry)
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Query) = {
		Query(
			m.`type`.orElse(`type`),
			m.`query`.orElse(`query`),
			m.`token`.orElse(`token`),
			m.`OBSOLETENoreply`.orElse(`OBSOLETENoreply`),
			`globalOptargs` ++ m.`globalOptargs`
		)
	}

	def getDefaultInstanceForType = Query.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
}

object Query {
	@reflect.BeanProperty val defaultInstance = new Query()

	def parseFrom(data: Array[Byte]): Query = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Query = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Query = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Query = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Query] = defaultInstance.mergeDelimitedFromStream(stream)

	val TYPE_FIELD_NUMBER = 1
	val QUERY_FIELD_NUMBER = 2
	val TOKEN_FIELD_NUMBER = 3
	val OBSOLETE_NOREPLY_FIELD_NUMBER = 4
	val GLOBAL_OPTARGS_FIELD_NUMBER = 6

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Query) = defaultInstance.mergeFrom(prototype)

	object QueryType extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val START = new EnumVal { val name = "START"; val id = 1 }
		val CONTINUE = new EnumVal { val name = "CONTINUE"; val id = 2 }
		val STOP = new EnumVal { val name = "STOP"; val id = 3 }

		val START_VALUE = 1
		val CONTINUE_VALUE = 2
		val STOP_VALUE = 3

		def valueOf(id: Int) = id match {
			case 1 => START
			case 2 => CONTINUE
			case 3 => STOP
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

	final case class AssocPair (
		`key`: Option[String] = None,
		`val`: Option[Term] = None
	) extends com.google.protobuf.GeneratedMessageLite
		with com.google.protobuf.MessageLite.Builder
		with net.sandrogrzicic.scalabuff.Message[AssocPair] {

		def setKey(_f: String) = copy(`key` = Some(_f))
		def setVal(_f: Term) = copy(`val` = Some(_f))

		def clearKey = copy(`key` = None)
		def clearVal = copy(`val` = None)

		def writeTo(output: com.google.protobuf.CodedOutputStream) {
			if (`key`.isDefined) output.writeString(1, `key`.get)
			if (`val`.isDefined) output.writeMessage(2, `val`.get)
		}

		lazy val getSerializedSize = {
			import com.google.protobuf.CodedOutputStream._
			var size = 0
			if (`key`.isDefined) size += computeStringSize(1, `key`.get)
			if (`val`.isDefined) size += computeMessageSize(2, `val`.get)

			size
		}

		def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): AssocPair = {
			import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
			var __key: Option[String] = `key`
			var __val: Option[Term] = `val`

			def __newMerged = AssocPair(
				__key,
				__val
			)
			while (true) in.readTag match {
				case 0 => return __newMerged
				case 10 => __key = Some(in.readString())
				case 18 => __val = Some(readMessage[Term](in, __val.orElse({
					__val = Term.defaultInstance
					__val
				}).get, _emptyRegistry))
				case default => if (!in.skipField(default)) return __newMerged
			}
			null
		}

		def mergeFrom(m: AssocPair) = {
			AssocPair(
				m.`key`.orElse(`key`),
				m.`val`.orElse(`val`)
			)
		}

		def getDefaultInstanceForType = AssocPair.defaultInstance
		def clear = getDefaultInstanceForType
		def isInitialized = true
		def build = this
		def buildPartial = this
		def newBuilderForType = getDefaultInstanceForType
		def toBuilder = this
	}

	object AssocPair {
		@reflect.BeanProperty val defaultInstance = new AssocPair()

		def parseFrom(data: Array[Byte]): AssocPair = defaultInstance.mergeFrom(data)
		def parseFrom(data: Array[Byte], offset: Int, length: Int): AssocPair = defaultInstance.mergeFrom(data, offset, length)
		def parseFrom(byteString: com.google.protobuf.ByteString): AssocPair = defaultInstance.mergeFrom(byteString)
		def parseFrom(stream: java.io.InputStream): AssocPair = defaultInstance.mergeFrom(stream)
		def parseDelimitedFrom(stream: java.io.InputStream): Option[AssocPair] = defaultInstance.mergeDelimitedFromStream(stream)

		val KEY_FIELD_NUMBER = 1
		val VAL_FIELD_NUMBER = 2

		def newBuilder = defaultInstance.newBuilderForType
		def newBuilder(prototype: AssocPair) = defaultInstance.mergeFrom(prototype)

	}
}
final case class Frame (
	`type`: Option[Frame.FrameType.EnumVal] = None,
	`pos`: Option[Long] = None,
	`opt`: Option[String] = None
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Frame] {

	def setType(_f: Frame.FrameType.EnumVal) = copy(`type` = Some(_f))
	def setPos(_f: Long) = copy(`pos` = Some(_f))
	def setOpt(_f: String) = copy(`opt` = Some(_f))

	def clearType = copy(`type` = None)
	def clearPos = copy(`pos` = None)
	def clearOpt = copy(`opt` = None)

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		if (`type`.isDefined) output.writeEnum(1, `type`.get)
		if (`pos`.isDefined) output.writeInt64(2, `pos`.get)
		if (`opt`.isDefined) output.writeString(3, `opt`.get)
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0
		if (`type`.isDefined) size += computeEnumSize(1, `type`.get)
		if (`pos`.isDefined) size += computeInt64Size(2, `pos`.get)
		if (`opt`.isDefined) size += computeStringSize(3, `opt`.get)

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Frame = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __type: Option[Frame.FrameType.EnumVal] = `type`
		var __pos: Option[Long] = `pos`
		var __opt: Option[String] = `opt`

		def __newMerged = Frame(
			__type,
			__pos,
			__opt
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 8 => __type = Some(Frame.FrameType.valueOf(in.readEnum()))
			case 16 => __pos = Some(in.readInt64())
			case 26 => __opt = Some(in.readString())
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Frame) = {
		Frame(
			m.`type`.orElse(`type`),
			m.`pos`.orElse(`pos`),
			m.`opt`.orElse(`opt`)
		)
	}

	def getDefaultInstanceForType = Frame.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
}

object Frame {
	@reflect.BeanProperty val defaultInstance = new Frame()

	def parseFrom(data: Array[Byte]): Frame = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Frame = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Frame = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Frame = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Frame] = defaultInstance.mergeDelimitedFromStream(stream)

	val TYPE_FIELD_NUMBER = 1
	val POS_FIELD_NUMBER = 2
	val OPT_FIELD_NUMBER = 3

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Frame) = defaultInstance.mergeFrom(prototype)

	object FrameType extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val POS = new EnumVal { val name = "POS"; val id = 1 }
		val OPT = new EnumVal { val name = "OPT"; val id = 2 }

		val POS_VALUE = 1
		val OPT_VALUE = 2

		def valueOf(id: Int) = id match {
			case 1 => POS
			case 2 => OPT
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

}
final case class Backtrace (
	`frames`: collection.immutable.Seq[Frame] = Vector.empty[Frame]
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Backtrace] {

	def setFrames(_i: Int, _v: Frame) = copy(`frames` = `frames`.updated(_i, _v))
	def addFrames(_f: Frame) = copy(`frames` = `frames` :+ _f)
	def addAllFrames(_f: Frame*) = copy(`frames` = `frames` ++ _f)
	def addAllFrames(_f: TraversableOnce[Frame]) = copy(`frames` = `frames` ++ _f)

	def clearFrames = copy(`frames` = Vector.empty[Frame])

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		for (_v <- `frames`) output.writeMessage(1, _v)
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0
		for (_v <- `frames`) size += computeMessageSize(1, _v)

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Backtrace = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		val __frames: collection.mutable.Buffer[Frame] = `frames`.toBuffer

		def __newMerged = Backtrace(
			Vector(__frames: _*)
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 10 => __frames += readMessage[Frame](in, Frame.defaultInstance, _emptyRegistry)
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Backtrace) = {
		Backtrace(
			`frames` ++ m.`frames`
		)
	}

	def getDefaultInstanceForType = Backtrace.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
}

object Backtrace {
	@reflect.BeanProperty val defaultInstance = new Backtrace()

	def parseFrom(data: Array[Byte]): Backtrace = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Backtrace = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Backtrace = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Backtrace = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Backtrace] = defaultInstance.mergeDelimitedFromStream(stream)

	val FRAMES_FIELD_NUMBER = 1

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Backtrace) = defaultInstance.mergeFrom(prototype)

}
final case class Response (
	`type`: Option[Response.ResponseType.EnumVal] = None,
	`token`: Option[Long] = None,
	`response`: collection.immutable.Seq[Datum] = Vector.empty[Datum],
	`backtrace`: Option[Backtrace] = None
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Response] {

	def setType(_f: Response.ResponseType.EnumVal) = copy(`type` = Some(_f))
	def setToken(_f: Long) = copy(`token` = Some(_f))
	def setResponse(_i: Int, _v: Datum) = copy(`response` = `response`.updated(_i, _v))
	def addResponse(_f: Datum) = copy(`response` = `response` :+ _f)
	def addAllResponse(_f: Datum*) = copy(`response` = `response` ++ _f)
	def addAllResponse(_f: TraversableOnce[Datum]) = copy(`response` = `response` ++ _f)
	def setBacktrace(_f: Backtrace) = copy(`backtrace` = Some(_f))

	def clearType = copy(`type` = None)
	def clearToken = copy(`token` = None)
	def clearResponse = copy(`response` = Vector.empty[Datum])
	def clearBacktrace = copy(`backtrace` = None)

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		if (`type`.isDefined) output.writeEnum(1, `type`.get)
		if (`token`.isDefined) output.writeInt64(2, `token`.get)
		for (_v <- `response`) output.writeMessage(3, _v)
		if (`backtrace`.isDefined) output.writeMessage(4, `backtrace`.get)
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0
		if (`type`.isDefined) size += computeEnumSize(1, `type`.get)
		if (`token`.isDefined) size += computeInt64Size(2, `token`.get)
		for (_v <- `response`) size += computeMessageSize(3, _v)
		if (`backtrace`.isDefined) size += computeMessageSize(4, `backtrace`.get)

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Response = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __type: Option[Response.ResponseType.EnumVal] = `type`
		var __token: Option[Long] = `token`
		val __response: collection.mutable.Buffer[Datum] = `response`.toBuffer
		var __backtrace: Option[Backtrace] = `backtrace`

		def __newMerged = Response(
			__type,
			__token,
			Vector(__response: _*),
			__backtrace
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 8 => __type = Some(Response.ResponseType.valueOf(in.readEnum()))
			case 16 => __token = Some(in.readInt64())
			case 26 => __response += readMessage[Datum](in, Datum.defaultInstance, _emptyRegistry)
			case 34 => __backtrace = Some(readMessage[Backtrace](in, __backtrace.orElse({
				__backtrace = Backtrace.defaultInstance
				__backtrace
			}).get, _emptyRegistry))
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Response) = {
		Response(
			m.`type`.orElse(`type`),
			m.`token`.orElse(`token`),
			`response` ++ m.`response`,
			m.`backtrace`.orElse(`backtrace`)
		)
	}

	def getDefaultInstanceForType = Response.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
}

object Response {
	@reflect.BeanProperty val defaultInstance = new Response()

	def parseFrom(data: Array[Byte]): Response = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Response = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Response = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Response = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Response] = defaultInstance.mergeDelimitedFromStream(stream)

	val TYPE_FIELD_NUMBER = 1
	val TOKEN_FIELD_NUMBER = 2
	val RESPONSE_FIELD_NUMBER = 3
	val BACKTRACE_FIELD_NUMBER = 4

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Response) = defaultInstance.mergeFrom(prototype)

	object ResponseType extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val SUCCESS_ATOM = new EnumVal { val name = "SUCCESS_ATOM"; val id = 1 }
		val SUCCESS_SEQUENCE = new EnumVal { val name = "SUCCESS_SEQUENCE"; val id = 2 }
		val SUCCESS_PARTIAL = new EnumVal { val name = "SUCCESS_PARTIAL"; val id = 3 }
		val CLIENT_ERROR = new EnumVal { val name = "CLIENT_ERROR"; val id = 16 }
		val COMPILE_ERROR = new EnumVal { val name = "COMPILE_ERROR"; val id = 17 }
		val RUNTIME_ERROR = new EnumVal { val name = "RUNTIME_ERROR"; val id = 18 }

		val SUCCESS_ATOM_VALUE = 1
		val SUCCESS_SEQUENCE_VALUE = 2
		val SUCCESS_PARTIAL_VALUE = 3
		val CLIENT_ERROR_VALUE = 16
		val COMPILE_ERROR_VALUE = 17
		val RUNTIME_ERROR_VALUE = 18

		def valueOf(id: Int) = id match {
			case 1 => SUCCESS_ATOM
			case 2 => SUCCESS_SEQUENCE
			case 3 => SUCCESS_PARTIAL
			case 16 => CLIENT_ERROR
			case 17 => COMPILE_ERROR
			case 18 => RUNTIME_ERROR
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

}
final case class Datum (
	`type`: Option[Datum.DatumType.EnumVal] = None,
	`rBool`: Option[Boolean] = None,
	`rNum`: Option[Double] = None,
	`rStr`: Option[String] = None,
	`rArray`: collection.immutable.Seq[Datum] = Vector.empty[Datum],
	`rObject`: collection.immutable.Seq[Datum.AssocPair] = Vector.empty[Datum.AssocPair]
) extends com.google.protobuf.GeneratedMessageLite.ExtendableMessage[Datum]
	with net.sandrogrzicic.scalabuff.ExtendableMessage[Datum] {

	def setType(_f: Datum.DatumType.EnumVal) = copy(`type` = Some(_f))
	def setRBool(_f: Boolean) = copy(`rBool` = Some(_f))
	def setRNum(_f: Double) = copy(`rNum` = Some(_f))
	def setRStr(_f: String) = copy(`rStr` = Some(_f))
	def setRArray(_i: Int, _v: Datum) = copy(`rArray` = `rArray`.updated(_i, _v))
	def addRArray(_f: Datum) = copy(`rArray` = `rArray` :+ _f)
	def addAllRArray(_f: Datum*) = copy(`rArray` = `rArray` ++ _f)
	def addAllRArray(_f: TraversableOnce[Datum]) = copy(`rArray` = `rArray` ++ _f)
	def setRObject(_i: Int, _v: Datum.AssocPair) = copy(`rObject` = `rObject`.updated(_i, _v))
	def addRObject(_f: Datum.AssocPair) = copy(`rObject` = `rObject` :+ _f)
	def addAllRObject(_f: Datum.AssocPair*) = copy(`rObject` = `rObject` ++ _f)
	def addAllRObject(_f: TraversableOnce[Datum.AssocPair]) = copy(`rObject` = `rObject` ++ _f)

	def clearType = copy(`type` = None)
	def clearRBool = copy(`rBool` = None)
	def clearRNum = copy(`rNum` = None)
	def clearRStr = copy(`rStr` = None)
	def clearRArray = copy(`rArray` = Vector.empty[Datum])
	def clearRObject = copy(`rObject` = Vector.empty[Datum.AssocPair])

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		if (`type`.isDefined) output.writeEnum(1, `type`.get)
		if (`rBool`.isDefined) output.writeBool(2, `rBool`.get)
		if (`rNum`.isDefined) output.writeDouble(3, `rNum`.get)
		if (`rStr`.isDefined) output.writeString(4, `rStr`.get)
		for (_v <- `rArray`) output.writeMessage(5, _v)
		for (_v <- `rObject`) output.writeMessage(6, _v)
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0
		if (`type`.isDefined) size += computeEnumSize(1, `type`.get)
		if (`rBool`.isDefined) size += computeBoolSize(2, `rBool`.get)
		if (`rNum`.isDefined) size += computeDoubleSize(3, `rNum`.get)
		if (`rStr`.isDefined) size += computeStringSize(4, `rStr`.get)
		for (_v <- `rArray`) size += computeMessageSize(5, _v)
		for (_v <- `rObject`) size += computeMessageSize(6, _v)

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Datum = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __type: Option[Datum.DatumType.EnumVal] = `type`
		var __rBool: Option[Boolean] = `rBool`
		var __rNum: Option[Double] = `rNum`
		var __rStr: Option[String] = `rStr`
		val __rArray: collection.mutable.Buffer[Datum] = `rArray`.toBuffer
		val __rObject: collection.mutable.Buffer[Datum.AssocPair] = `rObject`.toBuffer

		def __newMerged = Datum(
			__type,
			__rBool,
			__rNum,
			__rStr,
			Vector(__rArray: _*),
			Vector(__rObject: _*)
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 8 => __type = Some(Datum.DatumType.valueOf(in.readEnum()))
			case 16 => __rBool = Some(in.readBool())
			case 25 => __rNum = Some(in.readDouble())
			case 34 => __rStr = Some(in.readString())
			case 42 => __rArray += readMessage[Datum](in, Datum.defaultInstance, _emptyRegistry)
			case 50 => __rObject += readMessage[Datum.AssocPair](in, Datum.AssocPair.defaultInstance, _emptyRegistry)
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Datum) = {
		Datum(
			m.`type`.orElse(`type`),
			m.`rBool`.orElse(`rBool`),
			m.`rNum`.orElse(`rNum`),
			m.`rStr`.orElse(`rStr`),
			`rArray` ++ m.`rArray`,
			`rObject` ++ m.`rObject`
		)
	}

	def getDefaultInstanceForType = Datum.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = throw new RuntimeException("Method not available.")
	def toBuilder = throw new RuntimeException("Method not available.")
}

object Datum {
	@reflect.BeanProperty val defaultInstance = new Datum()

	def parseFrom(data: Array[Byte]): Datum = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Datum = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Datum = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Datum = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Datum] = defaultInstance.mergeDelimitedFromStream(stream)

	val TYPE_FIELD_NUMBER = 1
	val R_BOOL_FIELD_NUMBER = 2
	val R_NUM_FIELD_NUMBER = 3
	val R_STR_FIELD_NUMBER = 4
	val R_ARRAY_FIELD_NUMBER = 5
	val R_OBJECT_FIELD_NUMBER = 6

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Datum) = defaultInstance.mergeFrom(prototype)

	object DatumType extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val R_NULL = new EnumVal { val name = "R_NULL"; val id = 1 }
		val R_BOOL = new EnumVal { val name = "R_BOOL"; val id = 2 }
		val R_NUM = new EnumVal { val name = "R_NUM"; val id = 3 }
		val R_STR = new EnumVal { val name = "R_STR"; val id = 4 }
		val R_ARRAY = new EnumVal { val name = "R_ARRAY"; val id = 5 }
		val R_OBJECT = new EnumVal { val name = "R_OBJECT"; val id = 6 }

		val R_NULL_VALUE = 1
		val R_BOOL_VALUE = 2
		val R_NUM_VALUE = 3
		val R_STR_VALUE = 4
		val R_ARRAY_VALUE = 5
		val R_OBJECT_VALUE = 6

		def valueOf(id: Int) = id match {
			case 1 => R_NULL
			case 2 => R_BOOL
			case 3 => R_NUM
			case 4 => R_STR
			case 5 => R_ARRAY
			case 6 => R_OBJECT
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

	final case class AssocPair (
		`key`: Option[String] = None,
		`val`: Option[Datum] = None
	) extends com.google.protobuf.GeneratedMessageLite
		with com.google.protobuf.MessageLite.Builder
		with net.sandrogrzicic.scalabuff.Message[AssocPair] {

		def setKey(_f: String) = copy(`key` = Some(_f))
		def setVal(_f: Datum) = copy(`val` = Some(_f))

		def clearKey = copy(`key` = None)
		def clearVal = copy(`val` = None)

		def writeTo(output: com.google.protobuf.CodedOutputStream) {
			if (`key`.isDefined) output.writeString(1, `key`.get)
			if (`val`.isDefined) output.writeMessage(2, `val`.get)
		}

		lazy val getSerializedSize = {
			import com.google.protobuf.CodedOutputStream._
			var size = 0
			if (`key`.isDefined) size += computeStringSize(1, `key`.get)
			if (`val`.isDefined) size += computeMessageSize(2, `val`.get)

			size
		}

		def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): AssocPair = {
			import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
			var __key: Option[String] = `key`
			var __val: Option[Datum] = `val`

			def __newMerged = AssocPair(
				__key,
				__val
			)
			while (true) in.readTag match {
				case 0 => return __newMerged
				case 10 => __key = Some(in.readString())
				case 18 => __val = Some(readMessage[Datum](in, __val.orElse({
					__val = Datum.defaultInstance
					__val
				}).get, _emptyRegistry))
				case default => if (!in.skipField(default)) return __newMerged
			}
			null
		}

		def mergeFrom(m: AssocPair) = {
			AssocPair(
				m.`key`.orElse(`key`),
				m.`val`.orElse(`val`)
			)
		}

		def getDefaultInstanceForType = AssocPair.defaultInstance
		def clear = getDefaultInstanceForType
		def isInitialized = true
		def build = this
		def buildPartial = this
		def newBuilderForType = getDefaultInstanceForType
		def toBuilder = this
	}

	object AssocPair {
		@reflect.BeanProperty val defaultInstance = new AssocPair()

		def parseFrom(data: Array[Byte]): AssocPair = defaultInstance.mergeFrom(data)
		def parseFrom(data: Array[Byte], offset: Int, length: Int): AssocPair = defaultInstance.mergeFrom(data, offset, length)
		def parseFrom(byteString: com.google.protobuf.ByteString): AssocPair = defaultInstance.mergeFrom(byteString)
		def parseFrom(stream: java.io.InputStream): AssocPair = defaultInstance.mergeFrom(stream)
		def parseDelimitedFrom(stream: java.io.InputStream): Option[AssocPair] = defaultInstance.mergeDelimitedFromStream(stream)

		val KEY_FIELD_NUMBER = 1
		val VAL_FIELD_NUMBER = 2

		def newBuilder = defaultInstance.newBuilderForType
		def newBuilder(prototype: AssocPair) = defaultInstance.mergeFrom(prototype)

	}
}
final case class Term (
	`type`: Option[Term.TermType.EnumVal] = None,
	`datum`: Option[Datum] = None,
	`args`: collection.immutable.Seq[Term] = Vector.empty[Term],
	`optargs`: collection.immutable.Seq[Term.AssocPair] = Vector.empty[Term.AssocPair]
) extends com.google.protobuf.GeneratedMessageLite.ExtendableMessage[Term]
	with net.sandrogrzicic.scalabuff.ExtendableMessage[Term] {

	def setType(_f: Term.TermType.EnumVal) = copy(`type` = Some(_f))
	def setDatum(_f: Datum) = copy(`datum` = Some(_f))
	def setArgs(_i: Int, _v: Term) = copy(`args` = `args`.updated(_i, _v))
	def addArgs(_f: Term) = copy(`args` = `args` :+ _f)
	def addAllArgs(_f: Term*) = copy(`args` = `args` ++ _f)
	def addAllArgs(_f: TraversableOnce[Term]) = copy(`args` = `args` ++ _f)
	def setOptargs(_i: Int, _v: Term.AssocPair) = copy(`optargs` = `optargs`.updated(_i, _v))
	def addOptargs(_f: Term.AssocPair) = copy(`optargs` = `optargs` :+ _f)
	def addAllOptargs(_f: Term.AssocPair*) = copy(`optargs` = `optargs` ++ _f)
	def addAllOptargs(_f: TraversableOnce[Term.AssocPair]) = copy(`optargs` = `optargs` ++ _f)

	def clearType = copy(`type` = None)
	def clearDatum = copy(`datum` = None)
	def clearArgs = copy(`args` = Vector.empty[Term])
	def clearOptargs = copy(`optargs` = Vector.empty[Term.AssocPair])

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		if (`type`.isDefined) output.writeEnum(1, `type`.get)
		if (`datum`.isDefined) output.writeMessage(2, `datum`.get)
		for (_v <- `args`) output.writeMessage(3, _v)
		for (_v <- `optargs`) output.writeMessage(4, _v)
	}

	lazy val getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var size = 0
		if (`type`.isDefined) size += computeEnumSize(1, `type`.get)
		if (`datum`.isDefined) size += computeMessageSize(2, `datum`.get)
		for (_v <- `args`) size += computeMessageSize(3, _v)
		for (_v <- `optargs`) size += computeMessageSize(4, _v)

		size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Term = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __type: Option[Term.TermType.EnumVal] = `type`
		var __datum: Option[Datum] = `datum`
		val __args: collection.mutable.Buffer[Term] = `args`.toBuffer
		val __optargs: collection.mutable.Buffer[Term.AssocPair] = `optargs`.toBuffer

		def __newMerged = Term(
			__type,
			__datum,
			Vector(__args: _*),
			Vector(__optargs: _*)
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 8 => __type = Some(Term.TermType.valueOf(in.readEnum()))
			case 18 => __datum = Some(readMessage[Datum](in, __datum.orElse({
				__datum = Datum.defaultInstance
				__datum
			}).get, _emptyRegistry))
			case 26 => __args += readMessage[Term](in, Term.defaultInstance, _emptyRegistry)
			case 34 => __optargs += readMessage[Term.AssocPair](in, Term.AssocPair.defaultInstance, _emptyRegistry)
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Term) = {
		Term(
			m.`type`.orElse(`type`),
			m.`datum`.orElse(`datum`),
			`args` ++ m.`args`,
			`optargs` ++ m.`optargs`
		)
	}

	def getDefaultInstanceForType = Term.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def newBuilderForType = throw new RuntimeException("Method not available.")
	def toBuilder = throw new RuntimeException("Method not available.")
}

object Term {
	@reflect.BeanProperty val defaultInstance = new Term()

	def parseFrom(data: Array[Byte]): Term = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Term = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Term = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Term = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Term] = defaultInstance.mergeDelimitedFromStream(stream)

	val TYPE_FIELD_NUMBER = 1
	val DATUM_FIELD_NUMBER = 2
	val ARGS_FIELD_NUMBER = 3
	val OPTARGS_FIELD_NUMBER = 4

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Term) = defaultInstance.mergeFrom(prototype)

	object TermType extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val DATUM = new EnumVal { val name = "DATUM"; val id = 1 }
		val MAKE_ARRAY = new EnumVal { val name = "MAKE_ARRAY"; val id = 2 }
		val MAKE_OBJ = new EnumVal { val name = "MAKE_OBJ"; val id = 3 }
		val VAR = new EnumVal { val name = "VAR"; val id = 10 }
		val JAVASCRIPT = new EnumVal { val name = "JAVASCRIPT"; val id = 11 }
		val ERROR = new EnumVal { val name = "ERROR"; val id = 12 }
		val IMPLICIT_VAR = new EnumVal { val name = "IMPLICIT_VAR"; val id = 13 }
		val DB = new EnumVal { val name = "DB"; val id = 14 }
		val TABLE = new EnumVal { val name = "TABLE"; val id = 15 }
		val GET = new EnumVal { val name = "GET"; val id = 16 }
		val GET_ALL = new EnumVal { val name = "GET_ALL"; val id = 78 }
		val EQ = new EnumVal { val name = "EQ"; val id = 17 }
		val NE = new EnumVal { val name = "NE"; val id = 18 }
		val LT = new EnumVal { val name = "LT"; val id = 19 }
		val LE = new EnumVal { val name = "LE"; val id = 20 }
		val GT = new EnumVal { val name = "GT"; val id = 21 }
		val GE = new EnumVal { val name = "GE"; val id = 22 }
		val NOT = new EnumVal { val name = "NOT"; val id = 23 }
		val ADD = new EnumVal { val name = "ADD"; val id = 24 }
		val SUB = new EnumVal { val name = "SUB"; val id = 25 }
		val MUL = new EnumVal { val name = "MUL"; val id = 26 }
		val DIV = new EnumVal { val name = "DIV"; val id = 27 }
		val MOD = new EnumVal { val name = "MOD"; val id = 28 }
		val APPEND = new EnumVal { val name = "APPEND"; val id = 29 }
		val PREPEND = new EnumVal { val name = "PREPEND"; val id = 80 }
		val DIFFERENCE = new EnumVal { val name = "DIFFERENCE"; val id = 95 }
		val SET_INSERT = new EnumVal { val name = "SET_INSERT"; val id = 88 }
		val SET_INTERSECTION = new EnumVal { val name = "SET_INTERSECTION"; val id = 89 }
		val SET_UNION = new EnumVal { val name = "SET_UNION"; val id = 90 }
		val SET_DIFFERENCE = new EnumVal { val name = "SET_DIFFERENCE"; val id = 91 }
		val SLICE = new EnumVal { val name = "SLICE"; val id = 30 }
		val SKIP = new EnumVal { val name = "SKIP"; val id = 70 }
		val LIMIT = new EnumVal { val name = "LIMIT"; val id = 71 }
		val INDEXES_OF = new EnumVal { val name = "INDEXES_OF"; val id = 87 }
		val CONTAINS = new EnumVal { val name = "CONTAINS"; val id = 93 }
		val GET_FIELD = new EnumVal { val name = "GET_FIELD"; val id = 31 }
		val KEYS = new EnumVal { val name = "KEYS"; val id = 94 }
		val HAS_FIELDS = new EnumVal { val name = "HAS_FIELDS"; val id = 32 }
		val WITH_FIELDS = new EnumVal { val name = "WITH_FIELDS"; val id = 96 }
		val PLUCK = new EnumVal { val name = "PLUCK"; val id = 33 }
		val WITHOUT = new EnumVal { val name = "WITHOUT"; val id = 34 }
		val MERGE = new EnumVal { val name = "MERGE"; val id = 35 }
		val BETWEEN = new EnumVal { val name = "BETWEEN"; val id = 36 }
		val REDUCE = new EnumVal { val name = "REDUCE"; val id = 37 }
		val MAP = new EnumVal { val name = "MAP"; val id = 38 }
		val FILTER = new EnumVal { val name = "FILTER"; val id = 39 }
		val CONCATMAP = new EnumVal { val name = "CONCATMAP"; val id = 40 }
		val ORDERBY = new EnumVal { val name = "ORDERBY"; val id = 41 }
		val DISTINCT = new EnumVal { val name = "DISTINCT"; val id = 42 }
		val COUNT = new EnumVal { val name = "COUNT"; val id = 43 }
		val IS_EMPTY = new EnumVal { val name = "IS_EMPTY"; val id = 86 }
		val UNION = new EnumVal { val name = "UNION"; val id = 44 }
		val NTH = new EnumVal { val name = "NTH"; val id = 45 }
		val GROUPED_MAP_REDUCE = new EnumVal { val name = "GROUPED_MAP_REDUCE"; val id = 46 }
		val GROUPBY = new EnumVal { val name = "GROUPBY"; val id = 47 }
		val INNER_JOIN = new EnumVal { val name = "INNER_JOIN"; val id = 48 }
		val OUTER_JOIN = new EnumVal { val name = "OUTER_JOIN"; val id = 49 }
		val EQ_JOIN = new EnumVal { val name = "EQ_JOIN"; val id = 50 }
		val ZIP = new EnumVal { val name = "ZIP"; val id = 72 }
		val INSERT_AT = new EnumVal { val name = "INSERT_AT"; val id = 82 }
		val DELETE_AT = new EnumVal { val name = "DELETE_AT"; val id = 83 }
		val CHANGE_AT = new EnumVal { val name = "CHANGE_AT"; val id = 84 }
		val SPLICE_AT = new EnumVal { val name = "SPLICE_AT"; val id = 85 }
		val COERCE_TO = new EnumVal { val name = "COERCE_TO"; val id = 51 }
		val TYPEOF = new EnumVal { val name = "TYPEOF"; val id = 52 }
		val UPDATE = new EnumVal { val name = "UPDATE"; val id = 53 }
		val DELETE = new EnumVal { val name = "DELETE"; val id = 54 }
		val REPLACE = new EnumVal { val name = "REPLACE"; val id = 55 }
		val INSERT = new EnumVal { val name = "INSERT"; val id = 56 }
		val DB_CREATE = new EnumVal { val name = "DB_CREATE"; val id = 57 }
		val DB_DROP = new EnumVal { val name = "DB_DROP"; val id = 58 }
		val DB_LIST = new EnumVal { val name = "DB_LIST"; val id = 59 }
		val TABLE_CREATE = new EnumVal { val name = "TABLE_CREATE"; val id = 60 }
		val TABLE_DROP = new EnumVal { val name = "TABLE_DROP"; val id = 61 }
		val TABLE_LIST = new EnumVal { val name = "TABLE_LIST"; val id = 62 }
		val INDEX_CREATE = new EnumVal { val name = "INDEX_CREATE"; val id = 75 }
		val INDEX_DROP = new EnumVal { val name = "INDEX_DROP"; val id = 76 }
		val INDEX_LIST = new EnumVal { val name = "INDEX_LIST"; val id = 77 }
		val FUNCALL = new EnumVal { val name = "FUNCALL"; val id = 64 }
		val BRANCH = new EnumVal { val name = "BRANCH"; val id = 65 }
		val ANY = new EnumVal { val name = "ANY"; val id = 66 }
		val ALL = new EnumVal { val name = "ALL"; val id = 67 }
		val FOREACH = new EnumVal { val name = "FOREACH"; val id = 68 }
		val FUNC = new EnumVal { val name = "FUNC"; val id = 69 }
		val ASC = new EnumVal { val name = "ASC"; val id = 73 }
		val DESC = new EnumVal { val name = "DESC"; val id = 74 }
		val INFO = new EnumVal { val name = "INFO"; val id = 79 }
		val MATCH = new EnumVal { val name = "MATCH"; val id = 97 }
		val SAMPLE = new EnumVal { val name = "SAMPLE"; val id = 81 }
		val DEFAULT = new EnumVal { val name = "DEFAULT"; val id = 92 }
		val JSON = new EnumVal { val name = "JSON"; val id = 98 }

		val DATUM_VALUE = 1
		val MAKE_ARRAY_VALUE = 2
		val MAKE_OBJ_VALUE = 3
		val VAR_VALUE = 10
		val JAVASCRIPT_VALUE = 11
		val ERROR_VALUE = 12
		val IMPLICIT_VAR_VALUE = 13
		val DB_VALUE = 14
		val TABLE_VALUE = 15
		val GET_VALUE = 16
		val GET_ALL_VALUE = 78
		val EQ_VALUE = 17
		val NE_VALUE = 18
		val LT_VALUE = 19
		val LE_VALUE = 20
		val GT_VALUE = 21
		val GE_VALUE = 22
		val NOT_VALUE = 23
		val ADD_VALUE = 24
		val SUB_VALUE = 25
		val MUL_VALUE = 26
		val DIV_VALUE = 27
		val MOD_VALUE = 28
		val APPEND_VALUE = 29
		val PREPEND_VALUE = 80
		val DIFFERENCE_VALUE = 95
		val SET_INSERT_VALUE = 88
		val SET_INTERSECTION_VALUE = 89
		val SET_UNION_VALUE = 90
		val SET_DIFFERENCE_VALUE = 91
		val SLICE_VALUE = 30
		val SKIP_VALUE = 70
		val LIMIT_VALUE = 71
		val INDEXES_OF_VALUE = 87
		val CONTAINS_VALUE = 93
		val GET_FIELD_VALUE = 31
		val KEYS_VALUE = 94
		val HAS_FIELDS_VALUE = 32
		val WITH_FIELDS_VALUE = 96
		val PLUCK_VALUE = 33
		val WITHOUT_VALUE = 34
		val MERGE_VALUE = 35
		val BETWEEN_VALUE = 36
		val REDUCE_VALUE = 37
		val MAP_VALUE = 38
		val FILTER_VALUE = 39
		val CONCATMAP_VALUE = 40
		val ORDERBY_VALUE = 41
		val DISTINCT_VALUE = 42
		val COUNT_VALUE = 43
		val IS_EMPTY_VALUE = 86
		val UNION_VALUE = 44
		val NTH_VALUE = 45
		val GROUPED_MAP_REDUCE_VALUE = 46
		val GROUPBY_VALUE = 47
		val INNER_JOIN_VALUE = 48
		val OUTER_JOIN_VALUE = 49
		val EQ_JOIN_VALUE = 50
		val ZIP_VALUE = 72
		val INSERT_AT_VALUE = 82
		val DELETE_AT_VALUE = 83
		val CHANGE_AT_VALUE = 84
		val SPLICE_AT_VALUE = 85
		val COERCE_TO_VALUE = 51
		val TYPEOF_VALUE = 52
		val UPDATE_VALUE = 53
		val DELETE_VALUE = 54
		val REPLACE_VALUE = 55
		val INSERT_VALUE = 56
		val DB_CREATE_VALUE = 57
		val DB_DROP_VALUE = 58
		val DB_LIST_VALUE = 59
		val TABLE_CREATE_VALUE = 60
		val TABLE_DROP_VALUE = 61
		val TABLE_LIST_VALUE = 62
		val INDEX_CREATE_VALUE = 75
		val INDEX_DROP_VALUE = 76
		val INDEX_LIST_VALUE = 77
		val FUNCALL_VALUE = 64
		val BRANCH_VALUE = 65
		val ANY_VALUE = 66
		val ALL_VALUE = 67
		val FOREACH_VALUE = 68
		val FUNC_VALUE = 69
		val ASC_VALUE = 73
		val DESC_VALUE = 74
		val INFO_VALUE = 79
		val MATCH_VALUE = 97
		val SAMPLE_VALUE = 81
		val DEFAULT_VALUE = 92
		val JSON_VALUE = 98

		def valueOf(id: Int) = id match {
			case 1 => DATUM
			case 2 => MAKE_ARRAY
			case 3 => MAKE_OBJ
			case 10 => VAR
			case 11 => JAVASCRIPT
			case 12 => ERROR
			case 13 => IMPLICIT_VAR
			case 14 => DB
			case 15 => TABLE
			case 16 => GET
			case 78 => GET_ALL
			case 17 => EQ
			case 18 => NE
			case 19 => LT
			case 20 => LE
			case 21 => GT
			case 22 => GE
			case 23 => NOT
			case 24 => ADD
			case 25 => SUB
			case 26 => MUL
			case 27 => DIV
			case 28 => MOD
			case 29 => APPEND
			case 80 => PREPEND
			case 95 => DIFFERENCE
			case 88 => SET_INSERT
			case 89 => SET_INTERSECTION
			case 90 => SET_UNION
			case 91 => SET_DIFFERENCE
			case 30 => SLICE
			case 70 => SKIP
			case 71 => LIMIT
			case 87 => INDEXES_OF
			case 93 => CONTAINS
			case 31 => GET_FIELD
			case 94 => KEYS
			case 32 => HAS_FIELDS
			case 96 => WITH_FIELDS
			case 33 => PLUCK
			case 34 => WITHOUT
			case 35 => MERGE
			case 36 => BETWEEN
			case 37 => REDUCE
			case 38 => MAP
			case 39 => FILTER
			case 40 => CONCATMAP
			case 41 => ORDERBY
			case 42 => DISTINCT
			case 43 => COUNT
			case 86 => IS_EMPTY
			case 44 => UNION
			case 45 => NTH
			case 46 => GROUPED_MAP_REDUCE
			case 47 => GROUPBY
			case 48 => INNER_JOIN
			case 49 => OUTER_JOIN
			case 50 => EQ_JOIN
			case 72 => ZIP
			case 82 => INSERT_AT
			case 83 => DELETE_AT
			case 84 => CHANGE_AT
			case 85 => SPLICE_AT
			case 51 => COERCE_TO
			case 52 => TYPEOF
			case 53 => UPDATE
			case 54 => DELETE
			case 55 => REPLACE
			case 56 => INSERT
			case 57 => DB_CREATE
			case 58 => DB_DROP
			case 59 => DB_LIST
			case 60 => TABLE_CREATE
			case 61 => TABLE_DROP
			case 62 => TABLE_LIST
			case 75 => INDEX_CREATE
			case 76 => INDEX_DROP
			case 77 => INDEX_LIST
			case 64 => FUNCALL
			case 65 => BRANCH
			case 66 => ANY
			case 67 => ALL
			case 68 => FOREACH
			case 69 => FUNC
			case 73 => ASC
			case 74 => DESC
			case 79 => INFO
			case 97 => MATCH
			case 81 => SAMPLE
			case 92 => DEFAULT
			case 98 => JSON
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

	final case class AssocPair (
		`key`: Option[String] = None,
		`val`: Option[Term] = None
	) extends com.google.protobuf.GeneratedMessageLite
		with com.google.protobuf.MessageLite.Builder
		with net.sandrogrzicic.scalabuff.Message[AssocPair] {

		def setKey(_f: String) = copy(`key` = Some(_f))
		def setVal(_f: Term) = copy(`val` = Some(_f))

		def clearKey = copy(`key` = None)
		def clearVal = copy(`val` = None)

		def writeTo(output: com.google.protobuf.CodedOutputStream) {
			if (`key`.isDefined) output.writeString(1, `key`.get)
			if (`val`.isDefined) output.writeMessage(2, `val`.get)
		}

		lazy val getSerializedSize = {
			import com.google.protobuf.CodedOutputStream._
			var size = 0
			if (`key`.isDefined) size += computeStringSize(1, `key`.get)
			if (`val`.isDefined) size += computeMessageSize(2, `val`.get)

			size
		}

		def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): AssocPair = {
			import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
			var __key: Option[String] = `key`
			var __val: Option[Term] = `val`

			def __newMerged = AssocPair(
				__key,
				__val
			)
			while (true) in.readTag match {
				case 0 => return __newMerged
				case 10 => __key = Some(in.readString())
				case 18 => __val = Some(readMessage[Term](in, __val.orElse({
					__val = Term.defaultInstance
					__val
				}).get, _emptyRegistry))
				case default => if (!in.skipField(default)) return __newMerged
			}
			null
		}

		def mergeFrom(m: AssocPair) = {
			AssocPair(
				m.`key`.orElse(`key`),
				m.`val`.orElse(`val`)
			)
		}

		def getDefaultInstanceForType = AssocPair.defaultInstance
		def clear = getDefaultInstanceForType
		def isInitialized = true
		def build = this
		def buildPartial = this
		def newBuilderForType = getDefaultInstanceForType
		def toBuilder = this
	}

	object AssocPair {
		@reflect.BeanProperty val defaultInstance = new AssocPair()

		def parseFrom(data: Array[Byte]): AssocPair = defaultInstance.mergeFrom(data)
		def parseFrom(data: Array[Byte], offset: Int, length: Int): AssocPair = defaultInstance.mergeFrom(data, offset, length)
		def parseFrom(byteString: com.google.protobuf.ByteString): AssocPair = defaultInstance.mergeFrom(byteString)
		def parseFrom(stream: java.io.InputStream): AssocPair = defaultInstance.mergeFrom(stream)
		def parseDelimitedFrom(stream: java.io.InputStream): Option[AssocPair] = defaultInstance.mergeDelimitedFromStream(stream)

		val KEY_FIELD_NUMBER = 1
		val VAL_FIELD_NUMBER = 2

		def newBuilder = defaultInstance.newBuilderForType
		def newBuilder(prototype: AssocPair) = defaultInstance.mergeFrom(prototype)

	}
}

object Ql2 {
	def registerAllExtensions(registry: com.google.protobuf.ExtensionRegistryLite) {
	}

}
